# MyPentahoProject

This project showcases an ETL pipeline using Pentaho Data Integration (PDI). It extracts sales data from CSV, transforms it by cleaning and aggregating, and loads it into a MySQL database.

## Features
- Data cleaning & transformation (KTR)
- Job orchestration (KJB)
- Sample input/output files
- Diagrams of ETL workflow

## Tools Used
- Pentaho Data Integration (Spoon)
- MySQL
- CSV

## How to Run
1. Open `main_job.kjb` in Pentaho Spoon
2. Configure paths for input/output files
3. Run the job and check output
